{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intento con Pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "import fitz\n",
    "\n",
    "remove_pages={\n",
    "    \"Kasarakuy raymimanta\": (6, 7)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key=\"Kasarakuy raymimanta\"\n",
    "\n",
    "\n",
    "reader = PdfReader(f'data/{key}.pdf')\n",
    "number_of_pages = len(reader.pages)\n",
    "\n",
    "list_pages=range(remove_pages[key][0], number_of_pages-remove_pages[key][1])\n",
    "extracted=extract_text(\"data/{}.pdf\".format(key), page_numbers=list_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "doc = fitz.open(f'data/{key}.pdf')\n",
    "\n",
    "i=remove_pages[key][0]\n",
    "full_text=\"\"\n",
    "for page in doc.pages(remove_pages[key][0], number_of_pages-remove_pages[key][1]):\n",
    "    # print(\"Page number: \", i)\n",
    "    this_page_text=page.get_text(\"text\", sort=True).replace(\"\\n\", \" \")\n",
    "    this_page_text=re.sub(r'\\d+', '', this_page_text)\n",
    "    full_text+=this_page_text\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oraciones antes de filtrar:  1115\n",
      "Oraciones después de filtrar:  533\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from langdetect import detect\n",
    "\n",
    "sentences = sent_tokenize(full_text)\n",
    "non_spanish_sentences = []\n",
    "\n",
    "#Oraciones antes de filtrar\n",
    "print(\"Oraciones antes de filtrar: \", len(sentences))\n",
    "for sentence in sentences:\n",
    "    try:\n",
    "        if detect(sentence) != 'es':\n",
    "            non_spanish_sentences.append(sentence)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "sentences = non_spanish_sentences\n",
    "print(\"Oraciones después de filtrar: \", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a, aa, ch, chh, ch', ts, tr, h, i, ii, k, kh, k', l, ll, m, n, ñ, p, ph, p', q, qh, q', r, s, sh, t, th, t', u, uu, w, y\n",
    "alfabeto_quechua = ['a', 'aa', 'ch', 'chh', 'ch\\'', 'ts', 'tr', 'h', 'i', 'ii', 'k', 'kh', 'k\\'', 'l', 'll', 'm', 'n', 'ñ', 'p', 'ph', 'p\\'', 'q', 'qh', 'q\\'', 'r', 's', 'sh', 't', 'th', 't\\'', 'u', 'uu', 'w', 'y']\n",
    "\n",
    "def rule_based_heuristic(sentence):\n",
    "    #exclude sentences containing words formed by graphemes outside the alphabet\n",
    "    words = word_tokenize(sentence)\n",
    "    for word in words:\n",
    "        if word not in alfabeto_quechua:\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intento fallido con pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader, PdfWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las páginas iniciales y finales de los documentos que se quieren eliminar\n",
    "remove_pages={\n",
    "    \"Kasarakuy raymimanta\": (6, 7)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for key in remove_pages:\n",
    "    reader = PdfReader(f'data/{key}.pdf')\n",
    "    number_of_pages = len(reader.pages)\n",
    "    print(f'Number of pages: {number_of_pages}')\n",
    "\n",
    "    #Eliminar las páginas iniciales y finales\n",
    "    writer = PdfWriter()\n",
    "\n",
    "    for page in reader.pages[remove_pages[key][0]:-remove_pages[key][1]]:\n",
    "        writer.add_page(page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=writer.pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visitor_body(text, cm, tm, font_dict, font_size):\n",
    "    curr_font_size = font_size\n",
    "    print(f'{text} {curr_font_size} {font_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.extract_text()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
