{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline de extracción, este es el bueno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cess_esp to\n",
      "[nltk_data]     C:\\Users\\Maracuya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cess_esp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os \n",
    "\n",
    "nltk.download('cess_esp')\n",
    "from nltk.corpus import cess_esp\n",
    "#Por mejorar, este corpus está chiquito\n",
    "spanish_words = set(word for word in cess_esp.words())\n",
    "\n",
    "path = \"data/\"\n",
    "documents = []\n",
    "\n",
    "# Get all the PDF documents NAMES from the path\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        documents.append(file[:-4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_text_from_pdf(key):\n",
    "    doc = fitz.open(f'data/{key}.pdf')\n",
    "    number_of_pages = doc.page_count\n",
    "    full_text=\"\"\n",
    "    punctuation = '''!()-[]{};:'\"\\,<>./?_—’'''\n",
    "    regex = r'[^\\w\\s' + punctuation + ']' \n",
    "    for page in doc.pages():\n",
    "        this_page_text=page.get_text(\"text\", sort=True).replace(\"\\n\", \" \")\n",
    "        #Quitar caracteres especiales\n",
    "        this_page_text=re.sub(regex, '', this_page_text)\n",
    "        this_page_text=re.sub(r'\\d+', '', this_page_text)\n",
    "        \n",
    "        #Quitar más de un underscore, es para temas de completado en libros educativos\n",
    "        this_page_text = re.sub('_+', ' ', this_page_text)\n",
    "        #Quitar cualquier espacio o tabulación extra\n",
    "        this_page_text = re.sub('[ \\t]+', ' ', this_page_text)\n",
    "\n",
    "\n",
    "        this_page_text = this_page_text.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "        full_text+=this_page_text+\" \"\n",
    "    return full_text\n",
    "\n",
    "def get_all_text_from_pdf(key):\n",
    "    doc = fitz.open(f'data/{key}.pdf')\n",
    "    full_text=\" \".join([page.get_text(\"text\", sort=True).replace(\"\\n\", \" \") for page in doc])\n",
    "    full_text=re.sub(r'\\d+', '', full_text)\n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from langdetect import detect\n",
    "import langid\n",
    "\n",
    "def filtrar_espaniol(full_text):\n",
    "    sentences = sent_tokenize(full_text)\n",
    "    non_spanish_sentences = []\n",
    "\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        try:\n",
    "            languages=[]\n",
    "            languages.append(detect(sentence))\n",
    "            languages.append(langid.classify(sentence)[0])\n",
    "            if not any(lang in languages for lang in [\"es\", \"it\", \"ca\", \"pt\"]):\n",
    "                non_spanish_sentences.append(sentence)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    sentences = non_spanish_sentences\n",
    "    \n",
    "\n",
    "    return sentences\n",
    "\n",
    "def filtrar_oracion_espaniol(sentence):\n",
    "    try:\n",
    "        languages=[]\n",
    "        languages.append(detect(sentence))\n",
    "        languages.append(langid.classify(sentence)[0])\n",
    "        if not any(lang in languages for lang in [\"es\", \"it\", \"ca\", \"pt\"]):\n",
    "            return True\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funciones de filtrado\n",
    "alfabeto_quechua = ['a', 'aa', 'ch', 'chh', 'ch\\'', 'ts', 'tr', 'h', 'i', 'ii', 'k', 'kh', 'k\\'', 'l', 'll', 'm', 'n', 'ñ', 'p', 'ph', 'p\\'', 'q', 'qh', 'q\\'', 'r', 's', 'sh', 't', 'th', 't\\'', 'u', 'uu', 'w', 'y']\n",
    "\n",
    "def grafemas_no_en_alfabet(words):\n",
    "    for word in words:\n",
    "        for i, letter in enumerate(word):\n",
    "            #Continue  if letter is not a letter\n",
    "            if not letter.isalpha():\n",
    "                continue\n",
    "            if letter.lower() not in alfabeto_quechua:\n",
    "                #Chequear siguiente letra\n",
    "                if i+1 >= len(word):\n",
    "                    return False\n",
    "                letter = letter + word[i+1]\n",
    "                if letter.lower() not in alfabeto_quechua:\n",
    "                    if i+2 >= len(word):\n",
    "                        return False\n",
    "                    #Chequear siguiente letra\n",
    "                    letter = letter + word[i+2]\n",
    "                    if letter.lower() not in alfabeto_quechua:\n",
    "                        return False\n",
    "    return True\n",
    "\n",
    "#No funciona bien esta función, porque el detector de lenguaje no es muy bueno para palabras \n",
    "def oraciones_mucho_espaniol(words):\n",
    "    spanish_words = 0\n",
    "    for word in words:\n",
    "        try:\n",
    "            if detect(word) == 'es':\n",
    "                spanish_words += 1\n",
    "        except:\n",
    "            pass\n",
    "    return spanish_words/len(words) > 0.5\n",
    "\n",
    "def oracion_mucho_espaniol_v2(words):\n",
    "    palabras_encontradas = 0\n",
    "    #Usar un diccionario de palabras en español\n",
    "    for word in words:\n",
    "        if word.lower() in spanish_words:\n",
    "            palabras_encontradas += 1\n",
    "\n",
    "    return palabras_encontradas/len(words) < 0.25\n",
    "\n",
    "\n",
    "def oraciones_muy_cortas(words, min_length=3):\n",
    "    return len(words) > min_length\n",
    "\n",
    "def oraciones_muy_repititivas(words, threshold=0.5):\n",
    "    #Todo a minúsculas\n",
    "    words = [word.lower() for word in words]\n",
    "    \n",
    "    unique_words = set(words)\n",
    "    ratio = len(unique_words) / len(words)\n",
    "    return ratio >= threshold\n",
    "\n",
    "def palabras_muy_largas(words, threshold=40):\n",
    "    for word in words:\n",
    "        if len(word) > threshold:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def split_tokens(sentence):\n",
    "    #Esta expresión busca cualquier secuencia de 2 o más palabras que tengan cada una uno o dos caracteres de longitud, separadas por espacios.\n",
    "    #En el paper se indica que es para detectar partes de una palabra que se rompieron durante la extracción de texto debido al formato del pdf.\n",
    "    if re.search(r\"(\\b\\w{1,2}\\b\\s){2,}\", sentence):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def oraciones_con_matematica(sentence):\n",
    "    if re.search(r\"[\\d+\\-*/]+\", sentence):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a, aa, ch, chh, ch', ts, tr, h, i, ii, k, kh, k', l, ll, m, n, ñ, p, ph, p', q, qh, q', r, s, sh, t, th, t', u, uu, w, y\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Reglas basadas en https://aclanthology.org/2020.lrec-1.356/\n",
    "def rule_based_heuristic(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    aux_solo_palabras = [word for word in words if word.isalpha()]\n",
    "    \n",
    "    valid = oraciones_muy_cortas(aux_solo_palabras) \n",
    "    valid = valid and oraciones_muy_repititivas(aux_solo_palabras)\n",
    "    valid = valid and palabras_muy_largas(words)\n",
    "    valid = valid and split_tokens(sentence)\n",
    "    valid = valid and oraciones_con_matematica(sentence)\n",
    "    valid = valid and oracion_mucho_espaniol_v2(aux_solo_palabras)\n",
    "\n",
    "    return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(documents):\n",
    "    corpus=pd.DataFrame(columns=[\"document\", \"sentence\"])\n",
    "    for key in documents:\n",
    "        text=get_text_from_pdf(key)\n",
    "        sentences=sent_tokenize(text)\n",
    "        #Oraciones antes de filtrar\n",
    "        print(\"Oraciones antes de filtrar en documento \", key, \": \", len(sentences))\n",
    "        filtered_sentences=[]\n",
    "        for sentence in sentences:\n",
    "            if rule_based_heuristic(sentence) and filtrar_oracion_espaniol(sentence):\n",
    "                filtered_sentences.append(sentence)\n",
    "        \n",
    "        df=pd.DataFrame(filtered_sentences, columns=[\"sentence\"])\n",
    "        df[\"document\"]=key\n",
    "        #Quitar duplicados\n",
    "        df.drop_duplicates(subset=\"sentence\", inplace=True)\n",
    "        print(\"Oraciones después de filtrar en documento \", key, \": \", len(df))\n",
    "        corpus=pd.concat([corpus, df], ignore_index=True)\n",
    "    print(\"Total de oraciones: \", len(corpus))\n",
    "    corpus.drop_duplicates(subset=\"sentence\", inplace=True)\n",
    "    print(\"Total de oraciones únicas: \", len(corpus))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oraciones antes de filtrar en documento  1 Rimana. Qichwa - Qullawpi llamk'ana mayt'u. Cuaderno de trabajo - Comunicación 1° - Quechua Collao :  2291\n",
      "Oraciones después de filtrar en documento  1 Rimana. Qichwa - Qullawpi llamk'ana mayt'u. Cuaderno de trabajo - Comunicación 1° - Quechua Collao :  1362\n",
      "Oraciones antes de filtrar en documento  3 Rimana - Qillqasqa Mayt’u Qichwa Qullaw. Texto de Comunicación del 3° Secundaria - Quechua Collao :  1334\n",
      "Oraciones después de filtrar en documento  3 Rimana - Qillqasqa Mayt’u Qichwa Qullaw. Texto de Comunicación del 3° Secundaria - Quechua Collao :  727\n",
      "Oraciones antes de filtrar en documento  4 Rimana - Qillqasqa Mayt’u Qichwa Qullaw. Texto de Comunicación del 4° Secundaria - Quechua Collao :  1430\n",
      "Oraciones después de filtrar en documento  4 Rimana - Qillqasqa Mayt’u Qichwa Qullaw. Texto de Comunicación del 4° Secundaria - Quechua Collao :  782\n",
      "Oraciones antes de filtrar en documento  5 Rimana - Qillqasqa Mayt’u Qichwa Qullaw. Texto de Comunicación del 5° Secundaria - Quechua collao :  1471\n",
      "Oraciones después de filtrar en documento  5 Rimana - Qillqasqa Mayt’u Qichwa Qullaw. Texto de Comunicación del 5° Secundaria - Quechua collao :  792\n",
      "Oraciones antes de filtrar en documento  Alelipa munaqusqan waqaychanankuna. Historias y Relatos 5 - Inicial - Quechua Collao :  33\n",
      "Oraciones después de filtrar en documento  Alelipa munaqusqan waqaychanankuna. Historias y Relatos 5 - Inicial - Quechua Collao :  19\n",
      "Oraciones antes de filtrar en documento  Ayllunchikpa willakuyninkuna. Historias y relatos 2 - Inicial - Quechua Collao :  67\n",
      "Oraciones después de filtrar en documento  Ayllunchikpa willakuyninkuna. Historias y relatos 2 - Inicial - Quechua Collao :  46\n",
      "Oraciones antes de filtrar en documento  Kasarakuy raymimanta :  1139\n",
      "Oraciones después de filtrar en documento  Kasarakuy raymimanta :  461\n",
      "Oraciones antes de filtrar en documento  Liqichumanta. Historias y relatos 1 - Inicial - Quechua Collao :  20\n",
      "Oraciones después de filtrar en documento  Liqichumanta. Historias y relatos 1 - Inicial - Quechua Collao :  9\n",
      "Oraciones antes de filtrar en documento  Muhu papa rikch’arichiymanta. Historias y relatos 3 - Inicial - Quechua Collao :  18\n",
      "Oraciones después de filtrar en documento  Muhu papa rikch’arichiymanta. Historias y relatos 3 - Inicial - Quechua Collao :  8\n",
      "Oraciones antes de filtrar en documento  Papa allay. Historias y Relatos 4 - Inicial - Quechua Collao :  17\n",
      "Oraciones después de filtrar en documento  Papa allay. Historias y Relatos 4 - Inicial - Quechua Collao :  9\n",
      "Total de oraciones:  4215\n",
      "Total de oraciones únicas:  4183\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 Rimana. Qichwa - Qullawpi llamk'ana mayt'u. ...</td>\n",
       "      <td>Llamk'ana qillqana mayt'upin tarinki imaymana ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 Rimana. Qichwa - Qullawpi llamk'ana mayt'u. ...</td>\n",
       "      <td>Llamk'anaykipaqtaq yachachiqniyki, tayta mamay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 Rimana. Qichwa - Qullawpi llamk'ana mayt'u. ...</td>\n",
       "      <td>Watuchkaykuan qampaq allin kayninta hinallataq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 Rimana. Qichwa - Qullawpi llamk'ana mayt'u. ...</td>\n",
       "      <td>Kay llamk'ana qillqana mayt'uqa k}humpaykin ya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 Rimana. Qichwa - Qullawpi llamk'ana mayt'u. ...</td>\n",
       "      <td>Qillqayta, awinchayta kusisqalla yachay!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  1 Rimana. Qichwa - Qullawpi llamk'ana mayt'u. ...   \n",
       "1  1 Rimana. Qichwa - Qullawpi llamk'ana mayt'u. ...   \n",
       "2  1 Rimana. Qichwa - Qullawpi llamk'ana mayt'u. ...   \n",
       "3  1 Rimana. Qichwa - Qullawpi llamk'ana mayt'u. ...   \n",
       "4  1 Rimana. Qichwa - Qullawpi llamk'ana mayt'u. ...   \n",
       "\n",
       "                                            sentence  \n",
       "0  Llamk'ana qillqana mayt'upin tarinki imaymana ...  \n",
       "1  Llamk'anaykipaqtaq yachachiqniyki, tayta mamay...  \n",
       "2  Watuchkaykuan qampaq allin kayninta hinallataq...  \n",
       "3  Kay llamk'ana qillqana mayt'uqa k}humpaykin ya...  \n",
       "4           Qillqayta, awinchayta kusisqalla yachay!  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus=pipeline(documents)\n",
    "df_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imataq mikhuy waqaychayri Mikhuy waqaychayqa awpa runap kawsayninmantaraqmi.\n",
      "Khaynatan siqikurani kimsa watachayuq kachkaspay, kaytataq tawa watachayuq kaspay.\n",
      "Aleli nin: ataq kay wayqachay thantachaa chayqa, llakisqan karqani mana maypi llamkanachaykunata waqaychayta atispa.\n",
      "Huk punchawsi, uwihanta michichkaspa sipaschaqa liw, liw, liw nispa liqichup waqasqanta uyarisqa.\n",
      "Qillqap wachunkunata allinta awinchaspa, hamitasqaykimanhina qillqna maytuykipi qillqay.\n",
      "Chay pukllanapaqqa huk kachu runa akllakun.\n",
      "Imaynatataq Peru suyupiri khuchita uywanku?\n",
      "Manchana ayllu runakuna, imatam quriwan achalakuqku?\n",
      "Mana riqsisqa rimaykunata, llapan qillqata qhawarispa chuyanchanki.\n",
      "Sapa tuqupin utaq muhuta churasqaku, tukurquspaataqsi wakap wanunwan qatasqanku.\n"
     ]
    }
   ],
   "source": [
    "#Random sample\n",
    "for sentence in df_corpus.sample(10)['sentence'].values:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus.to_csv(\"data/corpus/corpus.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
